import re
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from gemini_client import get_gemini_answer
from utils import is_ml_related
from airtable_client import add_record


# ğŸ”¹ Metni normalize eden fonksiyon (kÃ¼Ã§Ã¼k harf, noktalama temizliÄŸi vs.)
def temizle(metin):
    stop_words = {"nedir", "ne", "nasÄ±l", "ile", "ve", "iÃ§in", "demektir", "?"}
    metin = metin.lower()
    metin = re.sub(r'[^\w\s]', '', metin)  # noktalama kaldÄ±r
    kelimeler = metin.split()
    temiz_kelimeler = [kelime for kelime in kelimeler if kelime not in stop_words]
    return ' '.join(temiz_kelimeler).strip()

# ğŸ”¹ TÃ¼rkÃ§e destekli gÃ¼Ã§lÃ¼ embedding modeli
embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

# ğŸ”¹ ChromaDB baÅŸlat
vector_db = Chroma(
    collection_name="soru_cevaplar",
    embedding_function=embedding_model,
    persist_directory="./chroma_db"
)

# ğŸ”¹ EÄŸer veritabanÄ± boÅŸsa Ã¶rnek verileri ekle (temizlenmiÅŸ haliyle!)
if vector_db._collection.count() == 0:
    print("ğŸ“¥ Ä°lk Ã¶rnek veri seti yÃ¼kleniyor...")

    orijinal_sorular = [
        ("Makine Ã¶ÄŸrenmesi nedir?", "Makine Ã¶ÄŸrenmesi, veriden Ã¶ÄŸrenen ve tahmin yapabilen algoritmalardÄ±r."),
        ("Denetimli Ã¶ÄŸrenme ne demektir?", "Denetimli Ã¶ÄŸrenme, etiketli veriyle modeli eÄŸitmektir."),
        ("Denetimsiz Ã¶ÄŸrenme nedir?", "Denetimsiz Ã¶ÄŸrenme, verideki yapÄ±larÄ± etiket olmadan keÅŸfetmektir."),
        ("Veri kÃ¼mesi nedir?", "Veri kÃ¼mesi, modelin Ã¶ÄŸrenmesi iÃ§in kullanÄ±lan Ã¶rnekler topluluÄŸudur."),
        ("Model nedir?", "Model, Ã¶ÄŸrenilen bilgiyi temsil eden matematiksel yapÄ±dÄ±r."),
        ("Overfitting nedir?", "Overfitting, modelin eÄŸitildiÄŸi veriye aÅŸÄ±rÄ± uyum saÄŸlamasÄ±dÄ±r."),
        ("AÅŸÄ±rÄ± Ã¶ÄŸrenme nedir?", "Overfitting, modelin eÄŸitildiÄŸi veriye aÅŸÄ±rÄ± uyum saÄŸlamasÄ±dÄ±r."),
        ("Accuracy nasÄ±l hesaplanÄ±r?", "DoÄŸruluk, doÄŸru tahminlerin toplam tahminlere oranÄ±dÄ±r."),
        ("DoÄŸruluk hesaplama nedir?", "DoÄŸruluk, doÄŸru tahminlerin toplam tahminlere oranÄ±dÄ±r."),
        ("EÄŸitim ve test verisi neden ayrÄ±lÄ±r?", "EÄŸitim verisi modelin Ã¶ÄŸrenmesi, test verisi performans deÄŸerlendirmesi iÃ§indir."),
        ("Lineer regresyon nedir?", "Lineer regresyon, doÄŸrusal iliÅŸki kurarak tahmin yapan bir yÃ¶ntemdir."),
        ("Lineer regresyon ne iÅŸe yarar?", "Lineer regresyon, doÄŸrusal iliÅŸki kurarak tahmin yapan bir yÃ¶ntemdir."),
        ("Scikit-learn ne iÅŸe yarar?", "Scikit-learn, Python'da makine Ã¶ÄŸrenmesi modelleri geliÅŸtirmek iÃ§in kullanÄ±lÄ±r.")
    ]

    sorular = [
        Document(page_content=temizle(soru), metadata={"cevap": cevap, "source": "manual"})
        for soru, cevap in orijinal_sorular
    ]

    vector_db.add_documents(sorular)
    vector_db.persist()
    print(f"âœ… {len(sorular)} Ã¶rnek soru baÅŸarÄ±yla eklendi.\n")

# ğŸ” KullanÄ±cÄ± ile etkileÅŸim
print("\nğŸ“Œ ML Soru-Cevap AsistanÄ±na HoÅŸ Geldiniz. Ã‡Ä±kmak iÃ§in 'q' yazÄ±n.\n")

while True:
    user_input = input("â“ Sorunuzu yazÄ±n: ").strip()

    if user_input.lower() in ["q", "Ã§Ä±k", "exit"]:
        print("ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
        break

    temiz_soru = temizle(user_input)
    sonuclar = vector_db.similarity_search_with_score(temiz_soru, k=3)

    en_iyi_sonuc = None
    en_iyi_skor = 1.0

    for doc, skor in sonuclar:
        if skor < en_iyi_skor:
            en_iyi_sonuc = doc
            en_iyi_skor = skor

    if en_iyi_skor < 0.8:
        source = en_iyi_sonuc.metadata.get("source", "unknown")
        if source == "manual":
            kaynak_bilgi = "ğŸ“š Ã–rnek veri setinden"
        elif source == "gemini":
            kaynak_bilgi = "ğŸ¤– Gemini API'den"
        else:
            kaynak_bilgi = "ğŸ“¥ Sonradan eklenmiÅŸ"

        print(f"ğŸ§  Cevap ({kaynak_bilgi}):\n{en_iyi_sonuc.metadata['cevap']}")
        continue


    # ğŸ’¡ VeritabanÄ±nda yoksa, ML ile ilgili mi kontrol et
    if not is_ml_related(user_input):
        print("âš ï¸ Bu soru makine Ã¶ÄŸrenmesiyle ilgili gÃ¶rÃ¼nmÃ¼yor, bu yÃ¼zden cevap verilmeyecek.")
        continue

    # ğŸŒ Gemini API'ye sor
    print("ğŸ¤– Gemini API'ye soruluyor...")
    yanit = get_gemini_answer(user_input)

    if yanit and "Gemini API'den yanÄ±t alÄ±namadÄ±" not in yanit:
        print(f"ğŸ§  Cevap (ğŸ¤– Gemini API'den):\n{yanit}")

        yeni_doc = Document(page_content=temiz_soru, metadata={"cevap": yanit, "source": "gemini"})
        vector_db.add_documents([yeni_doc])
        vector_db.persist()
        print("âœ… Yeni veri ChromaDBâ€™ye eklendi.")

        # ğŸ”— Airtableâ€™a da ekle
        add_record(user_input, yanit, source="gemini")
    else:
        print("âŒ Gemini'den yanÄ±t alÄ±namadÄ±.")
